"""
Build Drug Vector Database
å°†æ”¶é›†çš„è¯ç‰©æ•°æ®å‘é‡åŒ–å¹¶å­˜å‚¨åˆ° Chroma DB

ä½¿ç”¨æ–¹æ³•:
    python scripts/build_drug_vectordb.py
"""

# âœ… ç¬¬ä¸€æ­¥ï¼šåŠ è½½ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨æœ€å¼€å¤´ï¼‰
import os
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½é¡¹ç›®æ ¹ç›®å½•çš„ .env æ–‡ä»¶
project_root = Path(__file__).parent.parent
env_path = project_root / '.env'
load_dotenv(dotenv_path=env_path)

# éªŒè¯ API key
if not os.getenv('OPENAI_API_KEY'):
    print(f"âŒ Error: OPENAI_API_KEY not found")
    print(f"   Checked: {env_path}")
    print(f"   Please add OPENAI_API_KEY to .env file")
    import sys
    sys.exit(1)
else:
    print(f"âœ… API Key loaded from {env_path}")

# âœ… ç¬¬äºŒæ­¥ï¼šå…¶ä»–å¯¼å…¥
import sys
import json
from typing import List, Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(project_root))

try:
    # å°è¯•æ–°ç‰ˆæœ¬å¯¼å…¥ï¼ˆLangChain >= 0.1.0ï¼‰
    from langchain_openai import OpenAIEmbeddings
    from langchain_chroma import Chroma
except ImportError:
    # å›é€€åˆ°æ—§ç‰ˆæœ¬å¯¼å…¥
    from langchain.embeddings import OpenAIEmbeddings
    from langchain.vectorstores import Chroma

# Document çš„æ–°å¯¼å…¥è·¯å¾„
try:
    from langchain_core.documents import Document
except ImportError:
    from langchain.docstore.document import Document


class DrugVectorDBBuilder:
    """è¯ç‰©å‘é‡æ•°æ®åº“æ„å»ºå™¨"""
    
    def __init__(
        self, 
        data_dir: str = "data/drug_database",
        vector_db_dir: str = "data/drug_vectordb"
    ):
        self.data_dir = Path(data_dir)
        self.vector_db_dir = Path(vector_db_dir)
        self.embeddings = OpenAIEmbeddings()
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.vector_db_dir.mkdir(parents=True, exist_ok=True)
        
        self.stats = {
            'total_files': 0,
            'processed': 0,
            'failed': 0
        }
    
    def load_drug_data(self) -> List[Dict]:
        """
        åŠ è½½æ‰€æœ‰è¯ç‰©æ•°æ®
        
        Returns:
            è¯ç‰©æ•°æ®åˆ—è¡¨
        """
        drug_data = []
        
        if not self.data_dir.exists():
            print(f"âŒ Data directory not found: {self.data_dir}")
            print(f"   Please run collect_drug_data.py first!")
            return drug_data
        
        json_files = list(self.data_dir.glob("*.json"))
        self.stats['total_files'] = len(json_files)
        
        print(f"ğŸ“‚ Found {len(json_files)} drug data files")
        
        for filepath in json_files:
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    drug_data.append(data)
                    self.stats['processed'] += 1
            except Exception as e:
                print(f"âŒ Error loading {filepath}: {e}")
                self.stats['failed'] += 1
        
        print(f"âœ… Loaded {len(drug_data)} drug data files")
        return drug_data
    
    def create_documents(self, drug_data: List[Dict]) -> List[Document]:
        """
        å°†è¯ç‰©æ•°æ®è½¬æ¢ä¸º LangChain Documents
        
        Args:
            drug_data: è¯ç‰©æ•°æ®åˆ—è¡¨
            
        Returns:
            Document åˆ—è¡¨
        """
        documents = []
        
        print("ğŸ“ Creating documents...")
        
        for data in drug_data:
            drug_name = data.get('drug_name', 'Unknown')
            
            # åˆ›å»ºå¤šä¸ªæ–‡æ¡£ç‰‡æ®µï¼Œæé«˜æ£€ç´¢å‡†ç¡®æ€§
            
            # 1. åŸºæœ¬ä¿¡æ¯æ–‡æ¡£
            basic_info = f"""
Drug: {drug_name}
Generic Name: {data.get('generic_name', '')}
Brand Names: {', '.join(data.get('brand_names', []))}

Indications and Usage:
{data.get('indications', '')}

Dosage and Administration:
{data.get('dosage', '')}
""".strip()
            
            documents.append(Document(
                page_content=basic_info,
                metadata={
                    'drug_name': drug_name,
                    'doc_type': 'basic_info',
                    'source': 'FDA'
                }
            ))
            
            # 2. ç¦å¿Œç—‡å’Œè­¦å‘Šæ–‡æ¡£
            if data.get('contraindications') or data.get('warnings'):
                safety_info = f"""
Drug: {drug_name}

Contraindications:
{data.get('contraindications', '')}

Warnings and Precautions:
{data.get('warnings', '')}
""".strip()
                
                documents.append(Document(
                    page_content=safety_info,
                    metadata={
                        'drug_name': drug_name,
                        'doc_type': 'safety',
                        'source': 'FDA'
                    }
                ))
            
            # 3. ä¸è‰¯ååº”æ–‡æ¡£
            if data.get('adverse_reactions'):
                adverse_info = f"""
Drug: {drug_name}

Adverse Reactions:
{data.get('adverse_reactions', '')}
""".strip()
                
                documents.append(Document(
                    page_content=adverse_info,
                    metadata={
                        'drug_name': drug_name,
                        'doc_type': 'adverse_reactions',
                        'source': 'FDA'
                    }
                ))
            
            # 4. è¯ç‰©äº¤äº’ä½œç”¨æ–‡æ¡£
            if data.get('drug_interactions'):
                interaction_info = f"""
Drug: {drug_name}

Drug Interactions:
{data.get('drug_interactions', '')}
""".strip()
                
                documents.append(Document(
                    page_content=interaction_info,
                    metadata={
                        'drug_name': drug_name,
                        'doc_type': 'interactions',
                        'source': 'FDA'
                    }
                ))
            
            # 5. è¯ç†å­¦æ–‡æ¡£
            if data.get('pharmacology'):
                pharm_info = f"""
Drug: {drug_name}

Clinical Pharmacology:
{data.get('pharmacology', '')}
""".strip()
                
                documents.append(Document(
                    page_content=pharm_info,
                    metadata={
                        'drug_name': drug_name,
                        'doc_type': 'pharmacology',
                        'source': 'FDA'
                    }
                ))
        
        print(f"âœ… Created {len(documents)} documents from {len(drug_data)} drugs")
        return documents
    
    def build_vector_db(self, documents: List[Document]) -> Chroma:
        """
        æ„å»ºå‘é‡æ•°æ®åº“
        
        Args:
            documents: Document åˆ—è¡¨
            
        Returns:
            Chroma å‘é‡æ•°æ®åº“
        """
        print(f"ğŸ”¨ Building vector database...")
        print(f"   This may take a while (embedding {len(documents)} documents)...")
        
        # æ‰¹é‡å¤„ç†ï¼Œé¿å…ä¸€æ¬¡å¤„ç†å¤ªå¤š
        batch_size = 100
        vector_db = None
        
        for i in range(0, len(documents), batch_size):
            batch = documents[i:i+batch_size]
            print(f"   Processing batch {i//batch_size + 1}/{(len(documents)-1)//batch_size + 1}...")
            
            if vector_db is None:
                # ç¬¬ä¸€æ‰¹ï¼šåˆ›å»ºæ–°æ•°æ®åº“
                vector_db = Chroma.from_documents(
                    documents=batch,
                    embedding=self.embeddings,
                    persist_directory=str(self.vector_db_dir)
                )
            else:
                # åç»­æ‰¹æ¬¡ï¼šæ·»åŠ åˆ°ç°æœ‰æ•°æ®åº“
                vector_db.add_documents(batch)
        
        # æŒä¹…åŒ–
        # æŒä¹…åŒ–ï¼ˆæ–°ç‰ˆæœ¬è‡ªåŠ¨æŒä¹…åŒ–ï¼Œä¸éœ€è¦æ‰‹åŠ¨è°ƒç”¨ï¼‰
        print("ğŸ’¾ Vector database persisted automatically")
        # vector_db.persist()  # æ–°ç‰ˆæœ¬å·²ç§»é™¤æ­¤æ–¹æ³•
        
        print(f"âœ… Vector database built successfully!")
        print(f"   Location: {self.vector_db_dir}")
        print(f"   Total documents: {len(documents)}")
        
        return vector_db
    
    def build(self) -> None:
        """æ‰§è¡Œå®Œæ•´çš„æ„å»ºæµç¨‹"""
        print("="*60)
        print("ğŸš€ Building Drug Vector Database")
        print("="*60)
        
        # 1. åŠ è½½æ•°æ®
        drug_data = self.load_drug_data()
        
        if not drug_data:
            print("âŒ No drug data found. Please run collect_drug_data.py first!")
            return
        
        # 2. åˆ›å»ºæ–‡æ¡£
        documents = self.create_documents(drug_data)
        
        # 3. æ„å»ºå‘é‡æ•°æ®åº“
        vector_db = self.build_vector_db(documents)
        
        # 4. æµ‹è¯•æŸ¥è¯¢
        print("\n" + "="*60)
        print("ğŸ§ª Testing vector database...")
        print("="*60)
        
        test_queries = [
            "What are the side effects of Metformin?",
            "Warfarin drug interactions",
            "Aspirin contraindications"
        ]
        
        for query in test_queries:
            print(f"\nQuery: {query}")
            results = vector_db.similarity_search(query, k=2)
            for i, doc in enumerate(results, 1):
                print(f"  Result {i}: {doc.metadata['drug_name']} ({doc.metadata['doc_type']})")
                print(f"    Preview: {doc.page_content[:100]}...")
        
        # 5. æœ€ç»ˆç»Ÿè®¡
        print("\n" + "="*60)
        print("âœ… Build completed!")
        print("="*60)
        print(f"""
ğŸ“Š Statistics:
  Total drug data files: {self.stats['total_files']}
  Successfully processed: {self.stats['processed']}
  Failed: {self.stats['failed']}
  Total documents created: {len(documents)}
  Vector database location: {self.vector_db_dir}
""")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='Build drug vector database')
    parser.add_argument('--data-dir', type=str, default='data/drug_database',
                       help='Drug data directory (default: data/drug_database)')
    parser.add_argument('--output-dir', type=str, default='data/drug_vectordb',
                       help='Vector database output directory (default: data/drug_vectordb)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ„å»ºå™¨
    builder = DrugVectorDBBuilder(
        data_dir=args.data_dir,
        vector_db_dir=args.output_dir
    )
    
    # å¼€å§‹æ„å»º
    builder.build()


if __name__ == "__main__":
    main()